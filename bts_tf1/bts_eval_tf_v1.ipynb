{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "import fnmatch\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_path = './result_bts_nyu_v2/raw/'\n",
    "gt_path = '../dataset/nyu_depth_v2/official_splits/test/'\n",
    "dataset = 'nyu' \n",
    "min_depth_eval= 1e-3 \n",
    "max_depth_eval= 10 \n",
    "eigen_crop = True # crops according to Eigen NIPS14\n",
    "#garg_crop\n",
    "#do_kb_crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_errors(gt, pred):\n",
    "    thresh = np.maximum((gt / pred), (pred / gt))\n",
    "    d1 = (thresh < 1.25).mean()\n",
    "    d2 = (thresh < 1.25 ** 2).mean()\n",
    "    d3 = (thresh < 1.25 ** 3).mean()\n",
    "\n",
    "    rmse = (gt - pred) ** 2\n",
    "    rmse = np.sqrt(rmse.mean())\n",
    "\n",
    "    rmse_log = (np.log(gt) - np.log(pred)) ** 2\n",
    "    rmse_log = np.sqrt(rmse_log.mean())\n",
    "\n",
    "    abs_rel = np.mean(np.abs(gt - pred) / gt)\n",
    "    sq_rel = np.mean(((gt - pred)**2) / gt)\n",
    "\n",
    "    err = np.log(pred) - np.log(gt)\n",
    "    silog = np.sqrt(np.mean(err ** 2) - np.mean(err) ** 2) * 100\n",
    "\n",
    "    err = np.abs(np.log10(pred) - np.log10(gt))\n",
    "    log10 = np.mean(err)\n",
    "\n",
    "    return silog, log10, abs_rel, sq_rel, rmse, rmse_log, d1, d2, d3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def eval(pred_depths):\n",
    "\n",
    "    num_samples = len(pred_depths)\n",
    "    pred_depths_valid = []\n",
    "\n",
    "    i = 0\n",
    "    for t_id in range(num_samples):\n",
    "        if t_id in missing_ids:\n",
    "            continue\n",
    "\n",
    "        pred_depths_valid.append(pred_depths[t_id])\n",
    "\n",
    "    num_samples = num_samples - len(missing_ids)\n",
    "\n",
    "    silog = np.zeros(num_samples, np.float32)\n",
    "    log10 = np.zeros(num_samples, np.float32)\n",
    "    rms = np.zeros(num_samples, np.float32)\n",
    "    log_rms = np.zeros(num_samples, np.float32)\n",
    "    abs_rel = np.zeros(num_samples, np.float32)\n",
    "    sq_rel = np.zeros(num_samples, np.float32)\n",
    "    d1 = np.zeros(num_samples, np.float32)\n",
    "    d2 = np.zeros(num_samples, np.float32)\n",
    "    d3 = np.zeros(num_samples, np.float32)\n",
    "    \n",
    "    for i in range(num_samples):\n",
    "\n",
    "        gt_depth = gt_depths[i]\n",
    "        pred_depth = pred_depths_valid[i]\n",
    "\n",
    "        pred_depth[pred_depth < args.min_depth_eval] = args.min_depth_eval\n",
    "        pred_depth[pred_depth > args.max_depth_eval] = args.max_depth_eval\n",
    "        pred_depth[np.isinf(pred_depth)] = args.max_depth_eval\n",
    "\n",
    "        gt_depth[np.isinf(gt_depth)] = 0\n",
    "        gt_depth[np.isnan(gt_depth)] = 0\n",
    "\n",
    "        valid_mask = np.logical_and(gt_depth > args.min_depth_eval, gt_depth < args.max_depth_eval)\n",
    "\n",
    "        if args.do_kb_crop:\n",
    "            height, width = gt_depth.shape\n",
    "            top_margin = int(height - 352)\n",
    "            left_margin = int((width - 1216) / 2)\n",
    "            pred_depth_uncropped = np.zeros((height, width), dtype=np.float32)\n",
    "            pred_depth_uncropped[top_margin:top_margin + 352, left_margin:left_margin + 1216] = pred_depth\n",
    "            pred_depth = pred_depth_uncropped\n",
    "\n",
    "        if args.garg_crop or args.eigen_crop:\n",
    "            gt_height, gt_width = gt_depth.shape\n",
    "            eval_mask = np.zeros(valid_mask.shape)\n",
    "\n",
    "            if args.garg_crop:\n",
    "                eval_mask[int(0.40810811 * gt_height):int(0.99189189 * gt_height), int(0.03594771 * gt_width):int(0.96405229 * gt_width)] = 1\n",
    "\n",
    "            elif args.eigen_crop:\n",
    "                if args.dataset == 'kitti':\n",
    "                    eval_mask[int(0.3324324 * gt_height):int(0.91351351 * gt_height), int(0.0359477 * gt_width):int(0.96405229 * gt_width)] = 1\n",
    "                else:\n",
    "                    eval_mask[45:471, 41:601] = 1\n",
    "\n",
    "            valid_mask = np.logical_and(valid_mask, eval_mask)\n",
    "\n",
    "        silog[i], log10[i], abs_rel[i], sq_rel[i], rms[i], log_rms[i], d1[i], d2[i], d3[i] = compute_errors(gt_depth[valid_mask], pred_depth[valid_mask])\n",
    "\n",
    "    print(\"{:>7}, {:>7}, {:>7}, {:>7}, {:>7}, {:>7}, {:>7}, {:>7}, {:>7}\".format(\n",
    "        'd1', 'd2', 'd3', 'AbsRel', 'SqRel', 'RMSE', 'RMSElog', 'SILog', 'log10'))\n",
    "    print(\"{:7.3f}, {:7.3f}, {:7.3f}, {:7.3f}, {:7.3f}, {:7.3f}, {:7.3f}, {:7.3f}, {:7.3f}\".format(\n",
    "        d1.mean(), d2.mean(), d3.mean(),\n",
    "        abs_rel.mean(), sq_rel.mean(), rms.mean(), log_rms.mean(), silog.mean(), log10.mean()))\n",
    "\n",
    "    return silog, log10, abs_rel, sq_rel, rms, log_rms, d1, d2, d3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_depths = []\n",
    "missing_ids = set()\n",
    "pred_filenames = []\n",
    "\n",
    "for root, dirnames, filenames in os.walk(pred_path):\n",
    "    for pred_filename in fnmatch.filter(filenames, '*.png'):\n",
    "        if 'cmap' in pred_filename or 'gt' in pred_filename:\n",
    "            continue\n",
    "        dirname = root.replace(pred_path, '')\n",
    "        pred_filenames.append(os.path.join(dirname, pred_filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./result_bts_nyu_v2/raw/'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_test_samples = len(pred_filenames)\n",
    "\n",
    "pred_depths = []\n",
    "\n",
    "for i in range(num_test_samples):\n",
    "    pred_depth_path = os.path.join(args.pred_path, pred_filenames[i])\n",
    "    pred_depth = cv2.imread(pred_depth_path, -1)\n",
    "    if pred_depth is None:\n",
    "        print('Missing: %s ' % pred_depth_path)\n",
    "        missing_ids.add(i)\n",
    "        continue\n",
    "\n",
    "    if args.dataset == 'nyu':\n",
    "        pred_depth = pred_depth.astype(np.float32) / 1000.0\n",
    "    else:\n",
    "        pred_depth = pred_depth.astype(np.float32) / 256.0\n",
    "\n",
    "    pred_depths.append(pred_depth)\n",
    "\n",
    "print('Raw png files reading done')\n",
    "print('Evaluating {} files'.format(len(pred_depths)))\n",
    "\n",
    "if args.dataset == 'kitti':\n",
    "    for t_id in range(num_test_samples):\n",
    "        file_dir = pred_filenames[t_id].split('.')[0]\n",
    "        filename = file_dir.split('_')[-1]\n",
    "        directory = file_dir.replace('_' + filename, '')\n",
    "        gt_depth_path = os.path.join(args.gt_path, directory, 'proj_depth/groundtruth/image_02', filename + '.png')\n",
    "        depth = cv2.imread(gt_depth_path, -1)\n",
    "        if depth is None:\n",
    "            print('Missing: %s ' % gt_depth_path)\n",
    "            missing_ids.add(t_id)\n",
    "            continue\n",
    "\n",
    "        depth = depth.astype(np.float32) / 256.0\n",
    "        gt_depths.append(depth)\n",
    "\n",
    "elif args.dataset == 'nyu':\n",
    "    for t_id in range(num_test_samples):\n",
    "        file_dir = pred_filenames[t_id].split('.')[0]\n",
    "        filename = file_dir.split('_')[-1]\n",
    "        directory = file_dir.replace('_rgb_'+file_dir.split('_')[-1], '')\n",
    "        gt_depth_path = os.path.join(args.gt_path, directory, 'sync_depth_' + filename + '.png')\n",
    "        depth = cv2.imread(gt_depth_path, -1)\n",
    "        if depth is None:\n",
    "            print('Missing: %s ' % gt_depth_path)\n",
    "            missing_ids.add(t_id)\n",
    "            continue\n",
    "\n",
    "        depth = depth.astype(np.float32) / 1000.0\n",
    "        gt_depths.append(depth)\n",
    "\n",
    "print('GT files reading done')\n",
    "print('{} GT files missing'.format(len(missing_ids)))\n",
    "\n",
    "print('Computing errors')\n",
    "eval(pred_depths)\n",
    "\n",
    "print('Done.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
